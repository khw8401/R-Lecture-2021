accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(id~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_train$id)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(id~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_train$id)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
t <- table(pred, data_test$id)
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(id~., data_train)
colon
data <- colon[sample(nrow(colon)),]
colon$study <- factor(colon$study)
set.seed(2021)
k <- 5
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(study~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$study)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
colon
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(rx~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$rx)
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(time ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$time)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(time ~., data_train)
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(admit~., data_train)
ucla <- read.csv('https://stats.idre.ucla.edu/stat/data/binary.csv')
ucla$admit <-  factor(ucla$admit)
data <- ucla[sample(nrow(ucla)),]
set.seed(2021)
options(digits = 4)
# k=ford cv, k=5
k <-  5
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# Decision Tree
accuracy <- 0
precision <- 0
recall <- 0
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
dt <- rpart(admit~., data_train)
pred <- predict(dt, data_test, type='class')
t <- table(pred, data_test$admit)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
ucla
colon
colon
data <- colon[sample(nrow(colon)),]
colon$sex <- factor(colon$sex)
set.seed(2021)
k <- 5
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(sex ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$sex)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
data <- colon[sample(nrow(colon)),]
colon$status <- factor(colon$status)
set.seed(2021)
k <- 5
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
rf <- randomForest(status ~., data_train)
colon <-  na.omit(colon)
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
dt_avg_acc <- accuracy / k
colon <-  na.omit(colon)
data <- colon[sample(nrow(colon)),]
colon$status <- factor(colon$status)
set.seed(2021)
k <- 5
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
colon <-  na.omit(colon)
data <- colon[sample(nrow(colon)),]
colon$status <- factor(colon$status)
set.seed(2021)
k <- 5
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status~., data_train)
rf <- randomForest(status ~., data_train)
colon <-  na.omit(colon)
data <- colon[sample(nrow(colon)),]
colon <-  na.omit(colon)
data <- colon[sample(nrow(colon)),]
colon$status <- factor(colon$status)
set.seed(2021)
colon
k <- 5
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
library(caret)
library(class)
library(e1071)
library(randomForest)
library(rpart)
library(survival)
1번
colon <-  na.omit(colon)
data <- colon[sample(nrow(colon)),]
colon$status <- factor(colon$status)
set.seed(2021)
colon
k <- 5
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
test_list <- ((i-1)*q+1) : (i*q)
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
rf_avg_acc <- accuracy / k
rf_avg_prec <- precision / k
rf_avg_rec <- recall / k
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
rf_avg_acc <- accuracy / k
rf_avg_prec <- precision / k
rf_avg_rec <- recall / k
sprintf('랜덤 포레스트: 정확도=%f, 정밀도=%f, 재현율=%f',
rf_avg_acc, rf_avg_prec, rf_avg_rec)
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
sprintf('랜덤 포레스트: 정확도=%f, 정밀도=%f, 재현율=%f',
rf_avg_acc, rf_avg_prec, rf_avg_rec)
sprintf('랜덤 포레스트: 정확도=%f, rf_avg_acc)
sprintf('랜덤 포레스트: 정확도=%f,
rf_avg_acc)
sprintf('랜덤 포레스트: 정확도=%f, 정밀도=%f, 재현율=%f',
rf_avg_acc, rf_avg_prec, rf_avg_rec)
sprintf('랜덤 포레스트: 정확도=%f',
rf_avg_acc)
# k = 10
k <- 10
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
rf_avg_acc <- accuracy / k
rf_avg_prec <- precision / k
rf_avg_rec <- recall / k
sprintf('랜덤 포레스트: 정확도=%f',
rf_avg_acc)
# k = 15
k <- 15
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
rf_avg_acc <- accuracy / k
rf_avg_prec <- precision / k
rf_avg_rec <- recall / k
sprintf('랜덤 포레스트: 정확도=%f',
rf_avg_acc)
# k = 20
k <- 20
q <- nrow(data)/k
l <- 1:nrow(data)
accuracy <- 0
precision <- 0
recall <- 0
# random forest
for (i in 1:k) {
test_list <- ((i-1)*q+1) : (i*q)
data_test <- data[test_list,]
data_train <- data[-test_list,]
rf <- randomForest(status ~., data_train)
pred <- predict(rf, data_test, type='class')
t <- table(pred, data_test$status)
accuracy <- accuracy + (t[1,1]+t[2,2])/nrow(data_test)
precision <- precision + t[2,2]/(t[2,1]+t[2,2])
recall <- recall + t[2,2]/(t[1,2]+t[2,2])
}
rf_avg_acc <- accuracy / k
rf_avg_prec <- precision / k
rf_avg_rec <- recall / k
sprintf('랜덤 포레스트: 정확도=%f',
rf_avg_acc)
ucla <- read.csv('https://stats.idre.ucla.edu/stat/data/binary.csv')
ucla
clean_ucla=na.omit(ucla)
clean_ucla=clean_ucla[c(TRUE,FALSE),]
clean_ucla$admit=factor(clean_ucla$admit)
control=trainControl(method = 'cv',number = 10)
ucla
formula = admit~ gre+gpa+rank
formular = admit~ gre+gpa+rank
L=train(formular, data=clean_ucla, method='svmLinear',metric='Accuracy',trControl=control)
LW=train(formular, data = clean_ucla, method='svmLinearWeights',metric='Accuracy',trControl=control)
View(colon)
P = train(formular,data= clean_ucla, method='svmpoly',metric='Accuarcy',trControl=control)
library(caret)
P = train(formular,data= clean_ucla, method='svmpoly',metric='Accuarcy',trControl=control)
library(caret)
library(class)
library(e1071)
library(randomForest)
library(rpart)
library(survival)
library(caret)
clean_ucla=na.omit(ucla)
clean_ucla=clean_ucla[c(TRUE,FALSE),]
clean_ucla$admit=factor(clean_ucla$admit)
control=trainControl(method = 'cv',number = 10)
formular = admit~ gre+gpa+rank
L=train(formular, data=clean_ucla, method='svmLinear',metric='Accuracy',trControl=control)
LW=train(formular, data = clean_ucla, method='svmLinearWeights',metric='Accuracy',trControl=control)
P = train(formular,data= clean_ucla, method='svmpoly',metric='Accuarcy',trControl=control)
P = train(formular,data= clean_ucla, method='svmPoly',metric='Accuarcy',trControl=control)
R = train(formular,data= clean_ucla, method='svmRadial',metric='Accuarcy',trControl=control)
RW= train(formular,data= clean_ucla, method='svmRadialWeights',metric='Accuarcy',trControl=control)
f100=train(formular,data= clean_ucla, method='rf',ntree=100, metric='Accuarcy',trControl=control)
f300=train(formular,data= clean_ucla, method='rf',ntree=300, metric='Accuarcy',trControl=control)
f500=train(formular,data= clean_ucla, method='rf',ntree=500, metric='Accuarcy',trControl=control)
r=train(formular, data=clean_ucla, method='rpart',metric='Accuracy',trControl=control)
k=train(formular, data=clean_ucla, method='knn',metric='Accuracy',trControl=control)
g=train(formular, data=clean_ucla, method='glm',metric='Accuracy',trControl=control)
resamp=resamples(list(선형=L, 선형가중치=LW, 다항식=P, RBF=R, 가중치= RW, rf100=f100, rf300=f300
rf500=f500, tree=r, knn=k glm=g))
resamp=resamples(list(선형=L, 선형가중치=LW, 다항식=P, RBF=R, 가중치= RW, rf100=f100, rf300=f300,
rf500=f500, tree=r, knn=k glm=g))
resamp=resamples(list(선형=L, 선형가중치=LW, 다항식=P, RBF=R, 가중치= RW, rf100=f100, rf300=f300,
rf500=f500, tree=r, knn=k glm=g))
install.packages('rJava’)
install.packages('memoise’)
install.packages('hash’)
install.packages('tau’)
install.packages('Sejong’)
install.packages('devtools’)
install.packages('RSQLite')
install.packages('rJava’)
install.packages('rJava’)
install.packages('rJava’)
install.packages('RSQLite')
install.packages('devtools’)
install.packages('devtools’)
install.packages('Sejong’)
install.packages('tau’)
install.packages('memoise’)
install.packages('memoise’)
install.packages('rJava’)
install.packages('memoise’)
install.packages('hash’)
install.packages('tau’)
install.packages('Sejong’)
install.packages('devtools’)
install.packages('RSQLite')
install.packages('rJava')
install.packages('memoise')
install.packages('hash')
install.packages('tau')
install.packages('Sejong')
install.packages('devtools')
install.packages('RSQLite')
library(rJava)
install.packages("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.80.2.tar.gz", repos = NULL, type="source", INSTALL_opts = c('--no-lock’))
install.packages("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.80.2.tar.gz", repos = NULL, type="source", INSTALL_opts = c('--no-lock’))
install.packages("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.80.2.tar.gz", repos = NULL, type="source", INSTALL_opts = c('--no-lock'))
libPaths("C:/Users/CPB06GameN/Documents/R/win-library/4.0")
.libPaths("C:/Users/CPB06GameN/Documents/R/win-library/4.0")
.libPaths("C:/Users/CPB06GameN/Documents/R/win-library/4.0")
.libPaths("C:/Program Files/R/R-4.0.5/library")
.libPaths("C:/Users/CPB06GameN/Documents/R/win-library/4.0")
.libPaths("C:/Program Files/R/R-4.0.5/library")
.libPaths()
library(KoNLP)
library(KoNLP)
.libPaths()
library(KoNLP)
install.packages('rJava')
install.packages("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.80.2.tar.gz", repos = NULL, type="source", INSTALL_opts = c('--no-lock'))
.libPaths()
library(rJava)
install.packages('rJava')
install.packages("rJava")
install.packages("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.80.2.tar.gz", repos = NULL, type="source", INSTALL_opts = c('--no-lock'))
install.packages(("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.80.2.tar.gz", repos = NULL, type = "source", INSTALL_opts = c('--no-lock') )
install.packages("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.80.2.tar.gz", repos = NULL, type="source", INSTALL_opts = c('--no-lock'))
install.packages('rJava')
install.packages('memoise')
install.packages('hash')
install.packages('tau')
install.packages('Sejong')
install.packages('devtools')
install.packages('RSQLite')
.rs.listIndexedPackages()
install.packages("https://cran.r-project.org/src/contrib/Archive/KoNLP/KoNLP_0.08.2.tar.gz",repos = NULL, type = "source", INSTALL_opts = c('--no-lock'))
install.packages('rJava')
.libPaths()
renv::install("rstudio/renv")
install("rstudio/renv")
install.packages("rstudio/renv")
renv
install.packages('rJava')
install.packages('rJava')
install.packages('memoise)
getwd()
file.exists(tutorialsRoot)
.file.exists(tutorialsRoot)
file.exists(tutorialsRoot)
File file = new File ("path")
